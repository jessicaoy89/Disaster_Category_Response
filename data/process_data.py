"""
process_data.py is an ETL [extract transform load] pipeline that extracts the disaster categories and corresponding messages from csv files, cleans and transforms the data, then save the data into a database.

To run from command prompt in the file directory, type:

python process_data.py disaster_messages.csv disaster_categories.csv DisasterResponse.db

"""

import sys
import pandas as pd
import numpy as np
import sqlite3
from sqlalchemy import create_engine


def load_data(messages_filepath, categories_filepath):
    """
    load_data reads in disaster messages and categories files and merges them into a single dataframe
    
    ARGS:
        messages_filepath: path to disaster_messages.csv file (e.g. ../data/disaster_messages.csv)
        categories_filepath: path to disaster_categories.csv file (e.g. ../data/disaster_categories.csv)
    
    RETURNS:
        df: a dataframe with messages and categories merged together
    
    """
    # read in files
    messages = pd.read_csv(messages_filepath)
    categories = pd.read_csv(categories_filepath)
    # merge datasets
    df = categories.merge(messages, how='outer', on=['id'])
    return df


def clean_data(df):
    """
    clean_data cleans the input dataframe by:
        1. splitting categories
        2. converting category values to numbers 0 or 1
        3. replacing categories column with cleaned categories
        4. remove duplicate message and category pairs
        
    ARGS: 
        df: a dataframe with messages and categories merged together, generated by load_data function
        
    RETURNS:
        df: a dataframe with cleaned and deduplicated messages and categories
    """
    # 1. split categories
    # create a dataframe of the 36 individual category columns
    categories = df.categories.str.split(";", expand=True)
    # select the first row of the categories dataframe
    row = categories.iloc[0]
    # use this row to extract a list of new column names for categories.
    category_colnames = []
    for i in range(row.size):
        category_colnames.append(row[i])
    # rename the columns of `categories`
    categories.columns = category_colnames
    
    # 2. convert category values to just numbers 0 or 1
    for column in categories:
        # set each value to be the last character of the string
        categories[column] = categories[column].str.split('-').str[1]
        # convert column from string to numeric
        categories[column] = categories[column].astype(int)
    
    # 3. replace `categories` column in `df` with new category columns
    # drop the original categories column from `df`
    df = df.drop(['categories'], axis=1)
    # concatenate the original dataframe with the new `categories` dataframe
    df = pd.concat([df, categories], axis=1)
    
    # 4. remove duplicates
    # check number of duplicates
    duplicate_All = df[df.duplicated()]
    print('Number of duplicates considering all columns is: ', len(duplicate_All))
    # drop duplicates
    df = df.drop_duplicates(subset=None, keep ='first', inplace=False)
    # check number of duplicates again
    duplicate_check = df[df.duplicated()]
    print('Number of duplicates after dropping duplicates: ', len(duplicate_check))
    return df
    
    
def save_data(df, database_filename):
    """
    save_data saves the dataframe to a database (e.g. DisasterResponse.db)
    
    ARGS:
        df: a dataframe with cleaned and deduplicated messages and categories generated from cleand_data function
        database_filename: path to save the database (e.g. ../data/DisasterResponse.db)
        
    RETURNS:
        no return values
    """
    engine = create_engine('sqlite:///' + database_filename)
    df.to_sql('DisasterMessages', engine, if_exists='replace', index=False)  

def main():
    """
    main reads in input arguments and run the three functions: load_data, clean_data, and save_data.
    """
    if len(sys.argv) == 4:

        messages_filepath, categories_filepath, database_filepath = sys.argv[1:]

        print('Loading data...\n    MESSAGES: {}\n    CATEGORIES: {}'
              .format(messages_filepath, categories_filepath))
        df = load_data(messages_filepath, categories_filepath)

        print('Cleaning data...')
        df = clean_data(df)
        
        print('Saving data...\n    DATABASE: {}'.format(database_filepath))
        save_data(df, database_filepath)
        
        print('Cleaned data saved to database!')
    
    else:
        print('Please provide the filepaths of the messages and categories '\
              'datasets as the first and second argument respectively, as '\
              'well as the filepath of the database to save the cleaned data '\
              'to as the third argument. \n\nExample: python process_data.py '\
              'disaster_messages.csv disaster_categories.csv '\
              'DisasterResponse.db')


if __name__ == '__main__':
    main()